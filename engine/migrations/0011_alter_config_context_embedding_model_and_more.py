# Generated by Django 5.0.1 on 2026-02-09 04:37

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('engine', '0010_alter_config_llm_model'),
    ]

    operations = [
        migrations.AlterField(
            model_name='config',
            name='context_embedding_model',
            field=models.CharField(choices=[('bge-m3', 'BGE M3 (1024 dims, 8K context) - 1.2GB ⭐ ✓'), ('nomic-embed-text', 'Nomic Embed Text (768 dims, 2K context) - 274MB ✓'), ('snowflake-arctic-embed2:568m', 'Snowflake Arctic 2 (1024 dims) - 1.2GB ✓')], default='bge-m3', help_text='Context model for groups/summaries (✓ = pulled). Use bge-m3 for best quality.', max_length=100),
        ),
        migrations.AlterField(
            model_name='config',
            name='fast_embedding_model',
            field=models.CharField(choices=[('mxbai-embed-large', 'Mxbai Embed Large (1024 dims, fast) - 669MB ⭐ ✓'), ('nomic-embed-text', 'Nomic Embed Text (768 dims) - 274MB ✓'), ('snowflake-arctic-embed:335m', 'Snowflake Arctic (1024 dims) - 669MB ✓')], default='mxbai-embed-large', help_text='Fast model for individual logs (✓ = pulled). Use mxbai for best speed.', max_length=100),
        ),
        migrations.AlterField(
            model_name='config',
            name='llm_model',
            field=models.CharField(choices=[('mistral:7b-instruct', 'Mistral 7B Instruct (8K context) - 4.4GB ✓'), ('qwen2.5:7b-instruct', 'Qwen 2.5 7B Instruct (32K context) - 4.7GB ✓'), ('llama3.1:8b', 'Llama 3.1 8B Base (128K context) - 4.9GB ✓'), ('qwen2.5:14b-instruct', 'Qwen 2.5 14B Instruct (32K context) - 9.0GB ⭐ ✓'), ('llama3.1:70b-instruct-q4_K_M', 'Llama 3.1 70B Instruct Q4 (128K context) - 42GB ✓')], default='qwen2.5:14b-instruct', help_text='Ollama model name for threat analysis (✓ = pulled and ready)', max_length=100),
        ),
    ]
