# Generated by Django 5.0.1 on 2026-02-09 04:10

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('engine', '0008_remove_config_chunk_size_and_more'),
    ]

    operations = [
        migrations.AlterField(
            model_name='config',
            name='context_embedding_model',
            field=models.CharField(choices=[('bge-m3', 'BGE M3 (8K context, best quality) - 1.2GB ⭐'), ('nomic-embed-text', 'Nomic Embed Text (2K context) - 274MB'), ('snowflake-arctic-embed2:568m', 'Snowflake Arctic Embed 2 (8K context) - 1.2GB')], default='bge-m3', help_text='Large context model for groups and summaries', max_length=100),
        ),
        migrations.AlterField(
            model_name='config',
            name='fast_embedding_model',
            field=models.CharField(choices=[('mxbai-embed-large', 'Mxbai Embed Large (512 context) - 669MB ⭐'), ('nomic-embed-text', 'Nomic Embed Text (2K context) - 274MB'), ('snowflake-arctic-embed:335m', 'Snowflake Arctic Embed (8K context) - 669MB')], default='mxbai-embed-large', help_text='Fast model for embedding individual logs immediately', max_length=100),
        ),
        migrations.AlterField(
            model_name='config',
            name='llm_model',
            field=models.CharField(choices=[('mistral:7b-instruct', 'Mistral 7B Instruct (8K context) - 4.4GB'), ('qwen2.5:7b-instruct', 'Qwen 2.5 7B Instruct (32K context) - 4.7GB'), ('llama3.1:8b', 'Llama 3.1 8B (128K context) - 4.9GB'), ('qwen2.5:14b-instruct', 'Qwen 2.5 14B Instruct (32K context) - 9.0GB ⭐'), ('llama3.1:70b-instruct-q4_K_M', 'Llama 3.1 70B Instruct Q4 (128K context) - 42GB')], default='mistral:7b-instruct', help_text='Ollama model name for threat analysis', max_length=100),
        ),
    ]
